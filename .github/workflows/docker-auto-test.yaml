name: Testing pipeline

on:
  pull_request:
    branches:
      - "*"

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10.13"

      - name: Install Docker Compose
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose

      - name: Cache Poetry dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pypoetry
          key: ${{ runner.os }}-poetry-${{ hashFiles('backend/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: pip install poetry==1.6.1

      - name: Install backend dependencies
        run: |
          pip install --upgrade pip setuptools wheel
          cd backend
          poetry config virtualenvs.create false
          poetry install
          pip install pytest-github-actions-annotate-failures typing_extensions

      - name: Fix docker-compose.yml
        run: |
          sed -i 's/: true/: "true"/g; s/: false/: "false"/g' docker-compose.yml

      - name: Build and start services
        run: |
          docker-compose build
          docker-compose up -d

      - name: Run backend tests
        id: backend_tests
        run: |
          cd backend
          poetry run pytest --junitxml=pytest-results.xml
        env:
          LCFS_DB_HOST: localhost
          LCFS_DB_PORT: 5432
          LCFS_DB_USER: lcfs
          LCFS_DB_PASS: development_only
          LCFS_DB_BASE: lcfs
          LCFS_REDIS_HOST: localhost
          LCFS_REDIS_PORT: 6379
          LCFS_REDIS_PASSWORD: development_only
          APP_ENVIRONMENT: dev
          LCFS_CHES_CLIENT_ID: mock_client_id
          LCFS_CHES_CLIENT_SECRET: mock_client_secret
          LCFS_CHES_AUTH_URL: http://mock_auth_url
          LCFS_CHES_SENDER_EMAIL: noreply@gov.bc.ca
          LCFS_CHES_SENDER_NAME: Mock Notification System
          LCFS_CHES_EMAIL_URL: http://mock_email_url

      - name: Upload pytest results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-results
          path: backend/pytest-results.xml

      - name: Stop services
        if: always()
        run: docker-compose down

      - name: Publish Backend Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: backend/pytest-results.xml
          github_token: ${{ secrets.GITHUB_TOKEN }}
          comment_title: "Backend Test Results"
          check_name: "Backend Test Results"
          fail_on: "errors"
          report_individual_runs: "true"
          deduplicate_classes_by_file_name: "true"

      - name: Parse pytest results
        if: always()
        id: parse_backend_results
        run: |
          # Extract test summary from XML using xmlstarlet
          sudo apt-get install -y xmlstarlet

          # Set default values in case the file doesn't exist or command fails
          echo "backend_total=0" >> $GITHUB_ENV
          echo "backend_passed=0" >> $GITHUB_ENV
          echo "backend_failed=0" >> $GITHUB_ENV
          echo "backend_skipped=0" >> $GITHUB_ENV
          echo "backend_failures_detail=None" >> $GITHUB_ENV

          if [ -f backend/pytest-results.xml ]; then
            # Extract test counts
            TOTAL=$(xmlstarlet sel -t -v "//testsuite/@tests" backend/pytest-results.xml)
            FAILURES=$(xmlstarlet sel -t -v "//testsuite/@failures" backend/pytest-results.xml)
            ERRORS=$(xmlstarlet sel -t -v "//testsuite/@errors" backend/pytest-results.xml)
            SKIPPED=$(xmlstarlet sel -t -v "//testsuite/@skipped" backend/pytest-results.xml)
            
            # Calculate passed tests
            FAILED=$((FAILURES + ERRORS))
            PASSED=$((TOTAL - FAILED - SKIPPED))
            
            echo "backend_total=$TOTAL" >> $GITHUB_ENV
            echo "backend_passed=$PASSED" >> $GITHUB_ENV
            echo "backend_failed=$FAILED" >> $GITHUB_ENV
            echo "backend_skipped=$SKIPPED" >> $GITHUB_ENV
            
            # Extract failure details (up to 5 failures)
            if [ "$FAILED" -gt 0 ]; then
              FAILURES_DETAIL=$(xmlstarlet sel -t -m "//testcase[failure or error][position() <= 5]" -v "@classname" -o "." -v "@name" -o " - " -v "(failure|error)[1]/@message" -n backend/pytest-results.xml | sed -e ':a' -e 'N' -e '$!ba' -e 's/\n/\\n• /g')
              echo "backend_failures_detail=• $FAILURES_DETAIL" >> $GITHUB_ENV
            else
              echo "backend_failures_detail=None" >> $GITHUB_ENV
            fi
          fi

  frontend-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"

      - name: Cache npm dependencies
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci

      - name: Run frontend tests
        id: frontend_tests
        run: |
          cd frontend
          npm run test:run -- --reporter=junit --outputFile=vitest-results.xml
        env:
          CI: true

      - name: Upload Vitest results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: vitest-results
          path: frontend/vitest-results.xml

      - name: Publish Frontend Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: frontend/vitest-results.xml
          github_token: ${{ secrets.GITHUB_TOKEN }}
          comment_title: "Frontend Test Results"
          check_name: "Frontend Test Results"
          fail_on: "errors"
          report_individual_runs: "true"
          deduplicate_classes_by_file_name: "true"

      - name: Parse frontend results
        if: always()
        id: parse_frontend_results
        run: |
          # Extract test summary from XML using xmlstarlet
          sudo apt-get install -y xmlstarlet

          # Set default values in case the file doesn't exist or command fails
          echo "frontend_total=0" >> $GITHUB_ENV
          echo "frontend_passed=0" >> $GITHUB_ENV
          echo "frontend_failed=0" >> $GITHUB_ENV
          echo "frontend_skipped=0" >> $GITHUB_ENV
          echo "frontend_failures_detail=None" >> $GITHUB_ENV

          if [ -f frontend/vitest-results.xml ]; then
            # Extract test counts
            TOTAL=$(xmlstarlet sel -t -v "//testsuite/@tests" frontend/vitest-results.xml)
            FAILURES=$(xmlstarlet sel -t -v "//testsuite/@failures" frontend/vitest-results.xml)
            ERRORS=$(xmlstarlet sel -t -v "//testsuite/@errors" frontend/vitest-results.xml)
            SKIPPED=$(xmlstarlet sel -t -v "//testsuite/@skipped" frontend/vitest-results.xml)
            
            # Calculate passed tests
            FAILED=$((FAILURES + ERRORS))
            PASSED=$((TOTAL - FAILED - SKIPPED))
            
            echo "frontend_total=$TOTAL" >> $GITHUB_ENV
            echo "frontend_passed=$PASSED" >> $GITHUB_ENV
            echo "frontend_failed=$FAILED" >> $GITHUB_ENV
            echo "frontend_skipped=$SKIPPED" >> $GITHUB_ENV
            
            # Extract failure details (up to 5 failures)
            if [ "$FAILED" -gt 0 ]; then
              FAILURES_DETAIL=$(xmlstarlet sel -t -m "//testcase[failure or error][position() <= 5]" -v "@classname" -o "." -v "@name" -o " - " -v "(failure|error)[1]/@message" -n frontend/vitest-results.xml | sed -e ':a' -e 'N' -e '$!ba' -e 's/\n/\\n• /g')
              echo "frontend_failures_detail=• $FAILURES_DETAIL" >> $GITHUB_ENV
            else
              echo "frontend_failures_detail=None" >> $GITHUB_ENV
            fi
          fi

  send-teams-notification:
    needs: [backend-tests, frontend-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Get PR information
        id: pr_info
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const pr = context.payload.pull_request;
            if (!pr) {
              console.log('No PR information found, this might be a direct push.');
              return;
            }

            // Set outputs for use in the Teams notification
            core.setOutput('pr_number', pr.number);
            core.setOutput('pr_title', pr.title);
            core.setOutput('pr_url', pr.html_url);
            core.setOutput('pr_user', pr.user.login);
            core.setOutput('pr_user_avatar', pr.user.avatar_url);

      - name: Send Teams Notification
        if: always()
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            // Get the PR info from the previous step
            const prNumber = '${{ steps.pr_info.outputs.pr_number }}';
            const prTitle = '${{ steps.pr_info.outputs.pr_title }}';
            const prUrl = '${{ steps.pr_info.outputs.pr_url }}';
            const prUser = '${{ steps.pr_info.outputs.pr_user }}';
            const prUserAvatar = '${{ steps.pr_info.outputs.pr_user_avatar }}';

            // Get the test results
            const backendTotal = parseInt('${{ env.backend_total }}' || '0');
            const backendPassed = parseInt('${{ env.backend_passed }}' || '0');
            const backendFailed = parseInt('${{ env.backend_failed }}' || '0');
            const backendSkipped = parseInt('${{ env.backend_skipped }}' || '0');
            const backendFailuresDetail = '${{ env.backend_failures_detail }}';

            const frontendTotal = parseInt('${{ env.frontend_total }}' || '0');
            const frontendPassed = parseInt('${{ env.frontend_passed }}' || '0');
            const frontendFailed = parseInt('${{ env.frontend_failed }}' || '0');
            const frontendSkipped = parseInt('${{ env.frontend_skipped }}' || '0');
            const frontendFailuresDetail = '${{ env.frontend_failures_detail }}';

            // Determine overall status
            const backendStatus = backendFailed > 0 ? 'Failed ❌' : 'Passed ✅';
            const frontendStatus = frontendFailed > 0 ? 'Failed ❌' : 'Passed ✅';
            const overallStatus = 
              backendFailed > 0 || frontendFailed > 0 ? 'Failed ❌' : 
              backendTotal === 0 && frontendTotal === 0 ? 'No tests run ⚠️' :
              'Passed ✅';
            const color = 
              backendFailed > 0 || frontendFailed > 0 ? 'D73A49' : // red
              backendTotal === 0 && frontendTotal === 0 ? 'FBAB19' : // orange
              '2CBE4E'; // green

            // Create message text
            let message = `**Test Results for PR #${prNumber}: ${prTitle}**\n\n`;
            message += `**Overall Status**: ${overallStatus}\n\n`;

            if (backendTotal > 0) {
              message += `**Backend Tests**: ${backendStatus}\n`;
              message += `✅ ${backendPassed} passing | `;
              message += `❌ ${backendFailed} failing | `;
              message += `⚠️ ${backendSkipped} skipped\n\n`;
              
              if (backendFailed > 0 && backendFailuresDetail !== 'None') {
                message += `**Backend Failures**:\n${backendFailuresDetail}\n\n`;
              }
            }

            if (frontendTotal > 0) {
              message += `**Frontend Tests**: ${frontendStatus}\n`;
              message += `✅ ${frontendPassed} passing | `;
              message += `❌ ${frontendFailed} failing | `;
              message += `⚠️ ${frontendSkipped} skipped\n\n`;
              
              if (frontendFailed > 0 && frontendFailuresDetail !== 'None') {
                message += `**Frontend Failures**:\n${frontendFailuresDetail}\n\n`;
              }
            }

            message += `[View detailed test results](${prUrl})`;

            // Create a thread ID to group messages for the same PR
            const threadId = `pr-${prNumber}`;

            // Facts for the Teams card
            const facts = [
              { "name": "Pull Request", "value": `#${prNumber}` },
              { "name": "Branch", "value": context.payload.pull_request.head.ref },
              { "name": "Created By", "value": prUser },
              { "name": "Backend Status", "value": backendStatus },
              { "name": "Frontend Status", "value": frontendStatus }
            ];

            // Create the Teams message card
            const card = {
              "@type": "MessageCard",
              "@context": "http://schema.org/extensions",
              "themeColor": color,
              "summary": `Test Results for PR #${prNumber}`,
              "sections": [
                {
                  "activityTitle": `Test Results for PR #${prNumber}`,
                  "activitySubtitle": `Repository: ${context.repo.owner}/${context.repo.repo}`,
                  "activityImage": prUserAvatar,
                  "facts": facts,
                  "text": message,
                  "markdown": true
                }
              ],
              // Add correlation ID to group messages for the same PR
              "correlationId": threadId,
              "potentialAction": [
                {
                  "@type": "OpenUri",
                  "name": "View on GitHub",
                  "targets": [
                    {
                      "os": "default",
                      "uri": prUrl
                    }
                  ]
                }
              ]
            };

            // Send notification to Teams
            const webhookUrl = process.env.TEAMS_WEBHOOK_URL;
            if (!webhookUrl) {
              console.log('No Teams webhook URL provided. Skipping notification.');
              return;
            }

            const https = require('https');
            const url = new URL(webhookUrl);

            const options = {
              hostname: url.hostname,
              path: url.pathname + url.search,
              method: 'POST',
              headers: {
                'Content-Type': 'application/json'
              }
            };

            const req = https.request(options, (res) => {
              console.log(`Teams notification status: ${res.statusCode}`);
              
              res.on('data', (chunk) => {
                console.log(`Response: ${chunk}`);
              });
            });

            req.on('error', (error) => {
              console.error(`Error sending Teams notification: ${error}`);
              core.setFailed(`Failed to send Teams notification: ${error.message}`);
            });

            req.write(JSON.stringify(card));
            req.end();
        env:
          TEAMS_WEBHOOK_URL: ${{ secrets.TEAMS_WEBHOOK_URL }}
